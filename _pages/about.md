---
permalink: /
title: "Seoyoon Chae"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

ğŸ‘‹ I am a prospective PhD student working on efficient and reliable deep learning systems.  
My research focuses on making large-scale AI models more memory-efficient, deployable, and practical for real-world systems.

ğŸ” **My current interests include:**
- Model compression (quantization & sparsity)
- Memory-efficient inference for large language models (LLMs)
- KV-cache optimization for long-context decoding
- Hardware-aware algorithm design (FPGA / ASIC accelerators)
- Efficient dataflow and PIM architectures

---

## ğŸ¯ Research Vision

Modern AI models are becoming increasingly large and computationally demanding.  
I am interested in bridging the gap between algorithm design and hardware constraints â€” designing methods that are not only theoretically sound, but also efficient in memory, latency, and energy.

My long-term goal is to build scalable AI systems that are both intelligent and efficient.

---

## ğŸ§ª Current Research

### Memory-Efficient LLM Inference
- KV-cache quantization and adaptive precision scheduling  
- Tiling-based memory management strategies  
- Long-context reasoning efficiency analysis  

### Hardware-Aware Deep Learning
- FPGA-based DNN accelerators  
- Pipelined LayerNorm and Processing Elements array design  
- Dataflow optimization for CNN and transformer models  

---

## ğŸ“° News

- Oct 2025 â€” I presented a paper at the 22nd International SoC Design Conference (ISOCC). 
- Jun 2025 â€” I've attended the VLSI Symposium 2025.
- Mar 2025 â€” I've awarded the Extra-Curricular Challenge Scholarship.

---

## ğŸ“ Education

**[Your University Name]**  
PhD in [Your Department] (Year â€“ Present)

**Sungkyunkwan University**  
B.S. in Electronic and Electrical Engineering (2022 - 2026)

---

## ğŸ“¬ Contact

âœ‰ï¸ Email: sychaeee@g.skku.edu  
ğŸ’» GitHub: https://github.com/chae-sy
